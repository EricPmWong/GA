{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 2: Predicting Chronic Kidney Disease in Patients\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus on steps exploring data, building models and evaluating the models we build.\n",
    "\n",
    "There are three links you may find important:\n",
    "- [A set of chronic kidney disease (CKD) data and other biological factors](./chronic_kidney_disease_full.csv).\n",
    "- [The CKD data dictionary](./chronic_kidney_disease_header.txt).\n",
    "- [An article comparing the use of k-nearest neighbors and support vector machines on predicting CKD](./chronic_kidney_disease.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the problem.\n",
    "\n",
    "Suppose you're working for Mayo Clinic, widely recognized to be the top hospital in the United States. In your work, you've overheard nurses and doctors discuss test results, then arrive at a conclusion as to whether or not someone has developed a particular disease or condition. For example, you might overhear something like:\n",
    "\n",
    "> **Nurse**: Male 57 year-old patient presents with severe chest pain. FDP _(short for fibrin degradation product)_ was elevated at 13. We did an echo _(echocardiogram)_ and it was inconclusive.\n",
    "\n",
    "> **Doctor**: What was his interarm BP? _(blood pressure)_\n",
    "\n",
    "> **Nurse**: Systolic was 140 on the right; 110 on the left.\n",
    "\n",
    "> **Doctor**: Dammit, it's an aortic dissection! Get to the OR _(operating room)_ now!\n",
    "\n",
    "> _(intense music playing)_\n",
    "\n",
    "In this fictitious but [Shonda Rhimes-esque](https://en.wikipedia.org/wiki/Shonda_Rhimes#Grey's_Anatomy,_Private_Practice,_Scandal_and_other_projects_with_ABC) scenario, you might imagine the doctor going through a series of steps like a [flowchart](https://en.wikipedia.org/wiki/Flowchart), or a series of if-this-then-that steps to diagnose a patient. The first steps made the doctor ask what the interarm blood pressure was. Because interarm blood pressure took on the values it took on, the doctor diagnosed the patient with an aortic dissection.\n",
    "\n",
    "Your goal, as a research biostatistical data scientist at the nation's top hospital, is to develop a medical test that can improve upon our current diagnosis system for [chronic kidney disease (CKD)](https://www.mayoclinic.org/diseases-conditions/chronic-kidney-disease/symptoms-causes/syc-20354521).\n",
    "\n",
    "**Real-world problem**: Develop a medical diagnosis test that is better than our current diagnosis system for CKD.\n",
    "\n",
    "**Data science problem**: Develop a medical diagnosis test that reduces both the number of false positives and the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "     bgr  ...    pcv    wbcc  rbcc  htn   dm  cad  appet   pe  ane class  \n",
       "0  121.0  ...   44.0  7800.0   5.2  yes  yes   no   good   no   no   ckd  \n",
       "1    NaN  ...   38.0  6000.0   NaN   no   no   no   good   no   no   ckd  \n",
       "2  423.0  ...   31.0  7500.0   NaN   no  yes   no   poor   no  yes   ckd  \n",
       "3  117.0  ...   32.0  6700.0   3.9  yes   no   no   poor  yes  yes   ckd  \n",
       "4  106.0  ...   35.0  7300.0   4.6   no   no   no   good   no   no   ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "df = pd.read_csv('chronic_kidney_disease_full.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 25 columns):\n",
      "age      391 non-null float64\n",
      "bp       388 non-null float64\n",
      "sg       353 non-null float64\n",
      "al       354 non-null float64\n",
      "su       351 non-null float64\n",
      "rbc      248 non-null object\n",
      "pc       335 non-null object\n",
      "pcc      396 non-null object\n",
      "ba       396 non-null object\n",
      "bgr      356 non-null float64\n",
      "bu       381 non-null float64\n",
      "sc       383 non-null float64\n",
      "sod      313 non-null float64\n",
      "pot      312 non-null float64\n",
      "hemo     348 non-null float64\n",
      "pcv      329 non-null float64\n",
      "wbcc     294 non-null float64\n",
      "rbcc     269 non-null float64\n",
      "htn      398 non-null object\n",
      "dm       398 non-null object\n",
      "cad      398 non-null object\n",
      "appet    399 non-null object\n",
      "pe       399 non-null object\n",
      "ane      399 non-null object\n",
      "class    400 non-null object\n",
      "dtypes: float64(14), object(11)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check out the data dictionary. What are a few features or relationships you might be interested in checking out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Sodium is usually utilized by kidneys to extrete waste. Potassium, creatinine, and diabetes are related to chronic kidney conditions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 3. How much of the data is missing from each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age        9\n",
       "bp        12\n",
       "sg        47\n",
       "al        46\n",
       "su        49\n",
       "rbc      152\n",
       "pc        65\n",
       "pcc        4\n",
       "ba         4\n",
       "bgr       44\n",
       "bu        19\n",
       "sc        17\n",
       "sod       87\n",
       "pot       88\n",
       "hemo      52\n",
       "pcv       71\n",
       "wbcc     106\n",
       "rbcc     131\n",
       "htn        2\n",
       "dm         2\n",
       "cad        2\n",
       "appet      1\n",
       "pe         1\n",
       "ane        1\n",
       "class      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Suppose that I dropped every row that contained at least one missing value. (In the context of analysis with missing data, we call this a \"complete case analysis,\" because we keep only the complete cases!) How many rows would remain in our dataframe? What are at least two downsides to doing this?\n",
    "\n",
    "> There's a good visual on slide 15 of [this deck](https://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf) that shows what a complete case analysis looks like if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>14</th>\n",
       "      <th>20</th>\n",
       "      <th>22</th>\n",
       "      <th>27</th>\n",
       "      <th>48</th>\n",
       "      <th>58</th>\n",
       "      <th>71</th>\n",
       "      <th>...</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>48</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>68</td>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>69</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sg</th>\n",
       "      <td>1.005</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.015</td>\n",
       "      <td>1.025</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.005</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.025</td>\n",
       "      <td>1.025</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.025</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.025</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.025</td>\n",
       "      <td>1.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>al</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbc</th>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>normal</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pc</th>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>normal</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcc</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba</th>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bgr</th>\n",
       "      <td>117</td>\n",
       "      <td>70</td>\n",
       "      <td>380</td>\n",
       "      <td>157</td>\n",
       "      <td>173</td>\n",
       "      <td>95</td>\n",
       "      <td>264</td>\n",
       "      <td>70</td>\n",
       "      <td>253</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>85</td>\n",
       "      <td>133</td>\n",
       "      <td>117</td>\n",
       "      <td>137</td>\n",
       "      <td>140</td>\n",
       "      <td>75</td>\n",
       "      <td>100</td>\n",
       "      <td>114</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bu</th>\n",
       "      <td>56</td>\n",
       "      <td>107</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>148</td>\n",
       "      <td>163</td>\n",
       "      <td>87</td>\n",
       "      <td>32</td>\n",
       "      <td>142</td>\n",
       "      <td>92</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc</th>\n",
       "      <td>3.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sod</th>\n",
       "      <td>111</td>\n",
       "      <td>114</td>\n",
       "      <td>131</td>\n",
       "      <td>130</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>130</td>\n",
       "      <td>125</td>\n",
       "      <td>138</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>142</td>\n",
       "      <td>147</td>\n",
       "      <td>141</td>\n",
       "      <td>139</td>\n",
       "      <td>150</td>\n",
       "      <td>141</td>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pot</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemo</th>\n",
       "      <td>11.2</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10</td>\n",
       "      <td>10.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13</td>\n",
       "      <td>14.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcv</th>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wbcc</th>\n",
       "      <td>6700</td>\n",
       "      <td>12100</td>\n",
       "      <td>4500</td>\n",
       "      <td>11000</td>\n",
       "      <td>9200</td>\n",
       "      <td>6900</td>\n",
       "      <td>9600</td>\n",
       "      <td>18900</td>\n",
       "      <td>7200</td>\n",
       "      <td>14600</td>\n",
       "      <td>...</td>\n",
       "      <td>6300</td>\n",
       "      <td>5800</td>\n",
       "      <td>6600</td>\n",
       "      <td>7400</td>\n",
       "      <td>9500</td>\n",
       "      <td>6700</td>\n",
       "      <td>7800</td>\n",
       "      <td>6600</td>\n",
       "      <td>7200</td>\n",
       "      <td>6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbcc</th>\n",
       "      <td>3.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>htn</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dm</th>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cad</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appet</th>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>...</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pe</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ane</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>ckd</td>\n",
       "      <td>...</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              3           9           11        14          20          22   \\\n",
       "age            48          53          63        68          61          48   \n",
       "bp             70          90          70        80          80          80   \n",
       "sg          1.005        1.02        1.01      1.01       1.015       1.025   \n",
       "al              4           2           3         3           2           4   \n",
       "su              0           0           0         2           0           0   \n",
       "rbc        normal    abnormal    abnormal    normal    abnormal      normal   \n",
       "pc       abnormal    abnormal    abnormal  abnormal    abnormal    abnormal   \n",
       "pcc       present     present     present   present  notpresent  notpresent   \n",
       "ba     notpresent  notpresent  notpresent   present  notpresent  notpresent   \n",
       "bgr           117          70         380       157         173          95   \n",
       "bu             56         107          60        90         148         163   \n",
       "sc            3.8         7.2         2.7       4.1         3.9         7.7   \n",
       "sod           111         114         131       130         135         136   \n",
       "pot           2.5         3.7         4.2       6.4         5.2         3.8   \n",
       "hemo         11.2         9.5        10.8       5.6         7.7         9.8   \n",
       "pcv            32          29          32        16          24          32   \n",
       "wbcc         6700       12100        4500     11000        9200        6900   \n",
       "rbcc          3.9         3.7         3.8       2.6         3.2         3.4   \n",
       "htn           yes         yes         yes       yes         yes         yes   \n",
       "dm             no         yes         yes       yes         yes          no   \n",
       "cad            no          no          no       yes         yes          no   \n",
       "appet        poor        poor        poor      poor        poor        good   \n",
       "pe            yes          no         yes       yes         yes          no   \n",
       "ane           yes         yes          no        no         yes         yes   \n",
       "class         ckd         ckd         ckd       ckd         ckd         ckd   \n",
       "\n",
       "              27          48          58          71      ...             390  \\\n",
       "age            69          73          73          46     ...              52   \n",
       "bp             70          70          80          60     ...              80   \n",
       "sg           1.01       1.005        1.02        1.01     ...           1.025   \n",
       "al              3           0           2           1     ...               0   \n",
       "su              4           0           0           0     ...               0   \n",
       "rbc        normal      normal    abnormal      normal     ...          normal   \n",
       "pc       abnormal      normal    abnormal      normal     ...          normal   \n",
       "pcc    notpresent  notpresent  notpresent  notpresent     ...      notpresent   \n",
       "ba     notpresent  notpresent  notpresent  notpresent     ...      notpresent   \n",
       "bgr           264          70         253         163     ...              99   \n",
       "bu             87          32         142          92     ...              25   \n",
       "sc            2.7         0.9         4.6         3.3     ...             0.8   \n",
       "sod           130         125         138         141     ...             135   \n",
       "pot             4           4         5.8           4     ...             3.7   \n",
       "hemo         12.5          10        10.5         9.8     ...              15   \n",
       "pcv            37          29          33          28     ...              52   \n",
       "wbcc         9600       18900        7200       14600     ...            6300   \n",
       "rbcc          4.1         3.5         4.3         3.2     ...             5.3   \n",
       "htn           yes         yes         yes         yes     ...              no   \n",
       "dm            yes         yes         yes         yes     ...              no   \n",
       "cad           yes          no         yes          no     ...              no   \n",
       "appet        good        good        good        good     ...            good   \n",
       "pe            yes         yes          no          no     ...              no   \n",
       "ane            no          no          no          no     ...              no   \n",
       "class         ckd         ckd         ckd         ckd     ...          notckd   \n",
       "\n",
       "              391         392         393         394         395         396  \\\n",
       "age            36          57          43          50          55          42   \n",
       "bp             80          80          60          80          80          70   \n",
       "sg          1.025        1.02       1.025        1.02        1.02       1.025   \n",
       "al              0           0           0           0           0           0   \n",
       "su              0           0           0           0           0           0   \n",
       "rbc        normal      normal      normal      normal      normal      normal   \n",
       "pc         normal      normal      normal      normal      normal      normal   \n",
       "pcc    notpresent  notpresent  notpresent  notpresent  notpresent  notpresent   \n",
       "ba     notpresent  notpresent  notpresent  notpresent  notpresent  notpresent   \n",
       "bgr            85         133         117         137         140          75   \n",
       "bu             16          48          45          46          49          31   \n",
       "sc            1.1         1.2         0.7         0.8         0.5         1.2   \n",
       "sod           142         147         141         139         150         141   \n",
       "pot           4.1         4.3         4.4           5         4.9         3.5   \n",
       "hemo         15.6        14.8          13        14.1        15.7        16.5   \n",
       "pcv            44          46          54          45          47          54   \n",
       "wbcc         5800        6600        7400        9500        6700        7800   \n",
       "rbcc          6.3         5.5         5.4         4.6         4.9         6.2   \n",
       "htn            no          no          no          no          no          no   \n",
       "dm             no          no          no          no          no          no   \n",
       "cad            no          no          no          no          no          no   \n",
       "appet        good        good        good        good        good        good   \n",
       "pe             no          no          no          no          no          no   \n",
       "ane            no          no          no          no          no          no   \n",
       "class      notckd      notckd      notckd      notckd      notckd      notckd   \n",
       "\n",
       "              397         398         399  \n",
       "age            12          17          58  \n",
       "bp             80          60          80  \n",
       "sg           1.02       1.025       1.025  \n",
       "al              0           0           0  \n",
       "su              0           0           0  \n",
       "rbc        normal      normal      normal  \n",
       "pc         normal      normal      normal  \n",
       "pcc    notpresent  notpresent  notpresent  \n",
       "ba     notpresent  notpresent  notpresent  \n",
       "bgr           100         114         131  \n",
       "bu             26          50          18  \n",
       "sc            0.6           1         1.1  \n",
       "sod           137         135         141  \n",
       "pot           4.4         4.9         3.5  \n",
       "hemo         15.8        14.2        15.8  \n",
       "pcv            49          51          53  \n",
       "wbcc         6600        7200        6800  \n",
       "rbcc          5.4         5.9         6.1  \n",
       "htn            no          no          no  \n",
       "dm             no          no          no  \n",
       "cad            no          no          no  \n",
       "appet        good        good        good  \n",
       "pe             no          no          no  \n",
       "ane            no          no          no  \n",
       "class      notckd      notckd      notckd  \n",
       "\n",
       "[25 rows x 158 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 258 entries, 3 to 399\n",
      "Data columns (total 7 columns):\n",
      "sod      258 non-null float64\n",
      "pot      258 non-null float64\n",
      "su       258 non-null float64\n",
      "bgr      258 non-null float64\n",
      "dm       258 non-null object\n",
      "sc       258 non-null float64\n",
      "class    258 non-null object\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 16.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Going to drop Nans from axis not in features, and drop rows with features but still nan\n",
    "features = ['sod', 'pot', 'su', 'bgr', 'dm', 'sc','class']\n",
    "df = df[features]\n",
    "df.isnull().sum()\n",
    "df.dropna(inplace=True, axis=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We would only have 158 out of the original 400 rows. One downside is we lose too many sample values. The other issue is that having only complete test cases might give us a biased sample set. It may be possible that only 1 hospital filled out the data and it represents ONLY that hospital which may have some laden bias underneath. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Thinking critically about how our data were gathered, it's likely that these records were gathered by doctors and nurses. Brainstorm three potential areas (in addition to the missing data we've already discussed) where this data might be inaccurate or imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Doctors/Nurses are notorious for bad handwriting. Perhaps the data is complete but illegible. IF their diagnosis is incorrect it could also prove cause issues. Perhaps they don't have Chronic Kidney disease and perhaps KD is a symptom of an underlying condition like dehydration which would give unsual data values instead of the disease trying to be diagnosed. Lastly, readings can be impercise such as systolic vs diastolic blood pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 6. Suppose that I want to construct a model where no person who has CKD will ever be told that they do not have CKD. What (very simple) model can I create that will never tell a person with CKD that they do not have CKD?\n",
    "\n",
    "> Hint: Don't think about `statsmodels` or `scikit-learn` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: tell everyone they have CKD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. In problem 6, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Zeroing any false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Thinking ethically, what is at least one disadvantage to the model you described in problem 6?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: It could cause a lot of people to go through trouble, emotional pain, stress, uncessary testing and waste a lot of resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Suppose that I want to construct a model where a person who does not have CKD will ever be told that they do have CKD. What (very simple) model can I create that will accomplish this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Tell everyone they do not have CKD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. In problem 9, what common classification metric did we optimize for? Did we minimize false positives or negatives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: In this case it is zeroing any false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Thinking ethically, what is at least one disadvantage to the model you described in problem 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: If someone really has the disease it can a lot of problems if they aren't diagnosed properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Construct a logistic regression model in `sklearn` predicting class from the other variables. You may scale, select/drop, and engineer features as you wish - build a good model! Make sure, however, that you include at least one categorical/dummy feature and at least one quantitative feature.\n",
    "\n",
    "> Hint: Remember to do a train/test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>sc</th>\n",
       "      <th>dm_no</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>class_ckd</th>\n",
       "      <th>class_notckd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>142.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>114.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>131.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sod  pot   su    bgr    sc  dm_no  dm_yes  class_ckd  class_notckd\n",
       "3   111.0  2.5  0.0  117.0   3.8      1       0          1             0\n",
       "5   142.0  3.2  0.0   74.0   1.1      0       1          1             0\n",
       "6   104.0  4.0  0.0  100.0  24.0      1       0          1             0\n",
       "9   114.0  3.7  0.0   70.0   7.2      0       1          1             0\n",
       "11  131.0  4.2  0.0  380.0   2.7      0       1          1             0"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sod', 'pot', 'su', 'bgr', 'dm_yes', 'sc']\n",
    "X = df[features]\n",
    "y = df['class_ckd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.40124808e-01, -3.46629377e-01, -4.06323732e-01,\n",
       "        -6.45232449e-01, -6.31308740e-01, -4.65809131e-01],\n",
       "       [-4.42833179e-01, -2.19865815e-01, -4.06323732e-01,\n",
       "        -6.32085293e-01, -6.31308740e-01, -5.46293609e-01],\n",
       "       [-4.42833179e-01, -2.19865815e-01, -4.06323732e-01,\n",
       "        -1.85081985e-01, -6.31308740e-01, -5.73121768e-01],\n",
       "       [-7.19424777e-01,  1.28733980e-01, -4.06323732e-01,\n",
       "        -1.32493361e-01,  1.58401102e+00,  1.70977389e-02],\n",
       "       [ 2.48645814e-01, -1.56484034e-01, -4.06323732e-01,\n",
       "        -1.45640517e-01, -6.31308740e-01, -5.19465449e-01],\n",
       "       [-4.42833179e-01,  1.92115761e-01, -4.06323732e-01,\n",
       "         4.06540040e-01,  1.58401102e+00,  3.12207493e-01],\n",
       "       [ 2.48645814e-01,  1.28733980e-01, -4.06323732e-01,\n",
       "        -2.24523454e-01, -6.31308740e-01, -5.73121768e-01],\n",
       "       [-2.79457832e-02, -2.51556706e-01, -4.06323732e-01,\n",
       "        -3.29700702e-01, -6.31308740e-01, -1.43871218e-01],\n",
       "       [ 2.48645814e-01, -3.14938487e-01, -4.06323732e-01,\n",
       "        -4.61172263e-01, -6.31308740e-01, -4.38980971e-01],\n",
       "       [ 5.25237412e-01, -2.97204724e-02, -4.06323732e-01,\n",
       "        -5.53202356e-01, -6.31308740e-01, -4.38980971e-01],\n",
       "       [-1.13431217e+00,  9.70430895e-02, -4.06323732e-01,\n",
       "         8.66690503e-01,  1.58401102e+00,  8.48770681e-01],\n",
       "       [ 5.25237412e-01,  9.70430895e-02, -4.06323732e-01,\n",
       "        -3.95436483e-01, -6.31308740e-01, -4.12152812e-01],\n",
       "       [ 2.48645814e-01, -3.78320268e-01, -4.06323732e-01,\n",
       "         1.83038386e-01,  1.58401102e+00, -9.02148988e-02],\n",
       "       [ 1.63160380e+00,  1.28733980e-01, -4.06323732e-01,\n",
       "        -7.37262542e-01, -6.31308740e-01, -5.73121768e-01],\n",
       "       [ 5.25237412e-01, -1.88174925e-01, -4.06323732e-01,\n",
       "        -5.66349512e-01, -6.31308740e-01, -4.12152812e-01],\n",
       "       [-4.42833179e-01, -2.19865815e-01, -4.06323732e-01,\n",
       "        -4.87466576e-01, -6.31308740e-01, -5.99949928e-01],\n",
       "       [-1.66241582e-01,  2.23806651e-01,  2.39440771e+00,\n",
       "         2.37861346e+00,  1.58401102e+00, -1.43871218e-01],\n",
       "       [-3.04537381e-01, -2.51556706e-01,  5.27253414e-01,\n",
       "         8.92984816e-01, -6.31308740e-01, -2.78012015e-01],\n",
       "       [-2.79457832e-02,  3.82261104e-01,  5.27253414e-01,\n",
       "         8.66690503e-01,  1.58401102e+00, -1.70699377e-01],\n",
       "       [-1.13431217e+00, -5.05083830e-01,  5.27253414e-01,\n",
       "         1.91846299e+00, -6.31308740e-01, -2.78012015e-01],\n",
       "       [-3.04537381e-01, -3.46629377e-01, -4.06323732e-01,\n",
       "        -7.10968230e-01, -6.31308740e-01, -5.99949928e-01],\n",
       "       [ 9.40124808e-01,  6.53521990e-02, -4.06323732e-01,\n",
       "        -5.92643825e-01, -6.31308740e-01, -5.46293609e-01],\n",
       "       [ 2.48645814e-01,  1.97041806e-03,  1.46083056e+00,\n",
       "         2.75068479e-01,  1.58401102e+00,  1.19753675e+00],\n",
       "       [-7.19424777e-01, -2.19865815e-01, -4.06323732e-01,\n",
       "        -6.58379605e-01, -6.31308740e-01, -2.51183855e-01],\n",
       "       [ 8.01829009e-01,  1.28733980e-01, -4.06323732e-01,\n",
       "        -4.48025107e-01, -6.31308740e-01, -4.65809131e-01],\n",
       "       [-3.04537381e-01, -1.24793144e-01,  1.46083056e+00,\n",
       "        -2.73161119e-02,  1.58401102e+00,  1.78066695e-01],\n",
       "       [-2.24067856e+00, -3.46629377e-01, -4.06323732e-01,\n",
       "         2.11567033e+00,  1.58401102e+00, -3.85324652e-01],\n",
       "       [-1.82579117e+00, -3.46629377e-01, -4.06323732e-01,\n",
       "        -4.61172263e-01, -6.31308740e-01, -2.78012015e-01],\n",
       "       [ 1.21671641e+00,  3.36613085e-02, -4.06323732e-01,\n",
       "        -1.58787673e-01, -6.31308740e-01, -5.46293609e-01],\n",
       "       [ 1.10350016e-01, -1.24793144e-01, -4.06323732e-01,\n",
       "         8.14101879e-01, -6.31308740e-01, -4.65809131e-01],\n",
       "       [-4.42833179e-01, -2.83247596e-01, -4.06323732e-01,\n",
       "        -5.66349512e-01, -6.31308740e-01, -5.19465449e-01],\n",
       "       [-1.66241582e-01,  1.28733980e-01, -4.06323732e-01,\n",
       "        -8.81881259e-01, -6.31308740e-01, -5.19465449e-01],\n",
       "       [-3.04537381e-01, -2.19865815e-01, -4.06323732e-01,\n",
       "        -6.45232449e-01, -6.31308740e-01, -4.92637290e-01],\n",
       "       [ 1.07842061e+00, -2.19865815e-01, -4.06323732e-01,\n",
       "        -2.63964922e-01, -6.31308740e-01, -4.92637290e-01],\n",
       "       [ 1.21671641e+00, -3.46629377e-01, -4.06323732e-01,\n",
       "        -7.10968230e-01, -6.31308740e-01, -4.38980971e-01],\n",
       "       [ 5.25237412e-01, -2.51556706e-01, -4.06323732e-01,\n",
       "        -2.50817766e-01, -6.31308740e-01, -1.97527536e-01],\n",
       "       [-9.96016374e-01, -2.51556706e-01,  4.26156200e+00,\n",
       "         4.57418853e+00,  1.58401102e+00, -9.73042051e-03],\n",
       "       [ 1.10350016e-01,  6.53521990e-02, -4.06323732e-01,\n",
       "        -1.06199049e-01, -6.31308740e-01, -5.99949928e-01],\n",
       "       [ 3.86941613e-01,  1.97041806e-03, -4.06323732e-01,\n",
       "        -4.61172263e-01, -6.31308740e-01, -3.31668334e-01],\n",
       "       [-3.04537381e-01,  9.70430895e-02, -4.06323732e-01,\n",
       "        -3.16553546e-01, -6.31308740e-01,  6.87801724e-01],\n",
       "       [-5.81128978e-01,  1.60424870e-01, -4.06323732e-01,\n",
       "         1.65551987e+00,  1.58401102e+00,  3.39035652e-01],\n",
       "       [ 1.10350016e-01,  1.28733980e-01, -4.06323732e-01,\n",
       "        -6.97821073e-01, -6.31308740e-01, -5.99949928e-01],\n",
       "       [ 1.07842061e+00,  1.28733980e-01, -4.06323732e-01,\n",
       "        -1.45640517e-01, -6.31308740e-01, -5.99949928e-01],\n",
       "       [-1.66241582e-01,  2.55497542e-01,  5.27253414e-01,\n",
       "         1.27425234e+00,  1.58401102e+00,  4.19520130e-01],\n",
       "       [ 8.01829009e-01, -3.46629377e-01, -4.06323732e-01,\n",
       "        -4.34877951e-01, -6.31308740e-01, -4.65809131e-01],\n",
       "       [ 2.48645814e-01, -1.56484034e-01, -4.06323732e-01,\n",
       "        -6.18938137e-01, -6.31308740e-01, -4.92637290e-01],\n",
       "       [ 1.63160380e+00, -3.46629377e-01, -4.06323732e-01,\n",
       "        -6.67575802e-02, -6.31308740e-01, -5.99949928e-01],\n",
       "       [-4.42833179e-01,  3.36613085e-02, -4.06323732e-01,\n",
       "        -3.03406390e-01, -6.31308740e-01, -4.12152812e-01],\n",
       "       [ 2.48645814e-01,  3.36613085e-02, -4.06323732e-01,\n",
       "        -2.73161119e-02, -6.31308740e-01, -5.73121768e-01],\n",
       "       [ 1.07842061e+00,  9.70430895e-02, -4.06323732e-01,\n",
       "        -3.82289327e-01, -6.31308740e-01, -5.73121768e-01],\n",
       "       [-4.42833179e-01, -2.83247596e-01, -4.06323732e-01,\n",
       "        -5.66349512e-01, -6.31308740e-01, -5.19465449e-01],\n",
       "       [ 1.63160380e+00, -3.46629377e-01, -4.06323732e-01,\n",
       "        -1.98229141e-01, -6.31308740e-01, -5.99949928e-01],\n",
       "       [ 2.48645814e-01, -1.24793144e-01, -4.06323732e-01,\n",
       "         1.04155449e-01, -6.31308740e-01, -4.12152812e-01],\n",
       "       [-7.19424777e-01,  9.70430895e-02,  5.27253414e-01,\n",
       "         2.22479854e-01,  1.58401102e+00, -3.31668334e-01],\n",
       "       [ 8.01829009e-01, -2.83247596e-01, -4.06323732e-01,\n",
       "        -6.32085293e-01, -6.31308740e-01, -4.12152812e-01],\n",
       "       [ 2.48645814e-01, -3.46629377e-01, -4.06323732e-01,\n",
       "        -5.79496668e-01, -6.31308740e-01, -5.99949928e-01],\n",
       "       [-3.34704495e+00, -5.36774720e-01, -4.06323732e-01,\n",
       "         1.30054665e+00,  1.58401102e+00,  2.48528841e+00],\n",
       "       [-4.42833179e-01, -2.97204724e-02, -4.06323732e-01,\n",
       "        -6.71526761e-01, -6.31308740e-01, -4.12152812e-01],\n",
       "       [ 5.25237412e-01, -1.88174925e-01, -4.06323732e-01,\n",
       "        -5.53202356e-01, -6.31308740e-01, -4.12152812e-01],\n",
       "       [-1.66241582e-01, -1.24793144e-01, -4.06323732e-01,\n",
       "         6.56336006e-01,  1.58401102e+00, -5.19465449e-01],\n",
       "       [-3.04537381e-01,  1.97041806e-03, -4.06323732e-01,\n",
       "         2.52725125e-02,  1.58401102e+00,  3.39035652e-01],\n",
       "       [ 1.21671641e+00, -3.46629377e-01, -4.06323732e-01,\n",
       "        -5.66349512e-01, -6.31308740e-01, -5.99949928e-01],\n",
       "       [ 3.42944919e+00,  1.09036367e+01,  2.39440771e+00,\n",
       "         5.24864445e-01, -6.31308740e-01,  7.85092029e+00],\n",
       "       [-1.66241582e-01, -2.97204724e-02, -4.06323732e-01,\n",
       "        -6.45232449e-01,  1.58401102e+00, -3.04840174e-01],\n",
       "       [ 3.86941613e-01, -3.14938487e-01, -4.06323732e-01,\n",
       "        -8.02998322e-01, -6.31308740e-01, -5.99949928e-01]])"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss =StandardScaler()\n",
    "ss.fit(X_train)\n",
    "ss.transform(X_train)\n",
    "ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9430051813471503, 0.9384615384615385)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "logit.score(X_train, y_train), logit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.038135</td>\n",
       "      <td>-0.242512</td>\n",
       "      <td>0.515887</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>2.495946</td>\n",
       "      <td>2.810228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sod       pot        su       bgr    dm_yes        sc\n",
       "0 -0.038135 -0.242512  0.515887  0.013386  2.495946  2.810228"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_\n",
    "features = ['sod', 'pot', 'su', 'bgr', 'dm_yes', 'sc']\n",
    "pd.DataFrame(logit.coef_, columns= features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logit.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: Evaluate the model.\n",
    "\n",
    "### 13. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your quantitative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diabetes had one of the highest relations to having Chronic Kidney Disease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Based on your logistic regression model constructed in problem 12, interpret the coefficient of one of your categorical/dummy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DM Yes (meaning having Diabetes Milletus) was negatively correlated to not having CKD. \n",
    "#Another way is that Diabetes has a positive correlation to having CKD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Despite being a relatively simple model, logistic regression is very widely used in the real world. Why do you think that's the case? Name at least two advantages to using logistic regression as a modeling technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Logistic regression returns useable co-efficents and a more interpretable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Does it make sense to generate a confusion matrix on our training data or our test data? Why? Generate it on the proper data.\n",
    "\n",
    "> Hint: Once you've generated your predicted $y$ values and you have your observed $y$ values, then it will be easy to [generate a confusion matrix using sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict neg</th>\n",
       "      <th>predict pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual neg</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual pos</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predict neg  predict pos\n",
       "actual neg           36            0\n",
       "actual pos            4           25"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Data. Modeliing because we want to see if our training data is giving us a proper conclusion\n",
    "predictions = logit.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(cm, columns=['predict neg', 'predict pos'], index = ['actual neg', 'actual pos'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In this hospital case, we want to predict CKD. Do we want to optimize for sensitivity, specificity, or something else? Why? (If you don't think there's one clear answer, that's okay! There rarely is. Be sure to defend your conclusion!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We would want to optimize sensitiivty. Not being diagnosed with a chronic disease, espeically one which is chronic, would result in death, lawsuits, and hosts of other problems. We want to be able to correctly diagnose so we want to optimize our sensivity rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18 (BONUS). Write a function that will create an ROC curve for you, then plot the ROC curve.\n",
    "\n",
    "Here's a strategy you might consider:\n",
    "1. In order to even begin, you'll need some fit model. Use your logistic regression model from problem 12.\n",
    "2. We want to look at all values of your \"threshold\" - that is, anything where .predict() gives you above your threshold falls in the \"positive class,\" and anything that is below your threshold falls in the \"negative class.\" Start the threshold at 0.\n",
    "3. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "4. Increment your threshold by some \"step.\" Maybe set your step to be 0.01, or even smaller.\n",
    "5. At this value of your threshold, calculate the sensitivity and specificity. Store these values.\n",
    "6. Repeat steps 3 and 4 until you get to the threshold of 1.\n",
    "7. Plot the values of sensitivity and 1 - specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Suppose you're speaking with the biostatistics lead at Mayo Clinic, who asks you \"Why are unbalanced classes generally a problem? Are they a problem in this particular CKD analysis?\" How would you respond?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may have a hidden unabalanced class within something like Diabetus Milletus where there are 72 people with Diabetes vs 186 where we do not. Diabetus also is rather impactful to our model. Because of the imbalanced classes we may need to get more data and samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Suppose you're speaking with a doctor at Mayo Clinic who, despite being very smart, doesn't know much about data science or statistics. How would you explain why unbalanced classes are generally a problem to this doctor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I would take an extreme example. Say something like if we had 1 person with diabetes and that 1 person had Chronic Kidney Disease. Well our data is going to say that Diabetes is 100% correlated to Chronic Kidney Disease. Well that has to do more with sample size than imbalanced classes but image if I had 10 people with Diabetes and 990 who did not. It may look like 5 of the people with Diabetes gives us a rate of 50% but what if of the 1000 that 590 people had CKD. So in actuality an unbalanced class is giving us a very different ratio of explanation than large populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Let's create very unbalanced classes just for the sake of this example! Generate very unbalanced classes by [bootstrapping](http://stattrek.com/statistics/dictionary.aspx?definition=sampling_with_replacement) (a.k.a. random sampling with replacement) the majority class.\n",
    "\n",
    "1. The majority class are those individuals with CKD.\n",
    "2. Generate a random sample of size 4,600 of individuals who have CKD **with replacement**. (Consider setting a random seed for this part!)\n",
    "3. Create a new dataframe with the original data plus this random sample of data.\n",
    "4. Now we should have a dataset with 5,000 observations, of which only about 150 are non-CKD individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('chronic_kidney_disease_full.csv')\n",
    "choices = df[df['class'] == 'ckd']\n",
    "appendthis = choices.sample(n=4600, replace=True, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2520, 7)"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appendthis.shape\n",
    "newpd = pd.concat([df,appendthis], axis=0)\n",
    "newpd.shape\n",
    "features = ['sod', 'pot', 'su', 'bgr', 'dm', 'sc','class']\n",
    "newpd = newpd[features]\n",
    "newpd.dropna(inplace=True, axis=0)\n",
    "newpd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Build a logistic regression model on the unbalanced class data and evaluate its performance using whatever method(s) you see fit. How would you describe the impact of unbalanced classes on logistic regression as a classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sod      0\n",
       "pot      0\n",
       "su       0\n",
       "bgr      0\n",
       "dm       0\n",
       "sc       0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpd.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "newpd = pd.get_dummies(newpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['sod', 'pot', 'su', 'bgr', 'dm_yes', 'sc']\n",
    "X = newpd[features]\n",
    "y = newpd['class_ckd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.14201803, -0.27641103, -0.58991159, -0.50945913,  0.92650261,\n",
       "        -0.67151386],\n",
       "       [ 0.67383024, -0.08001372,  0.89964472, -0.12337284,  0.92650261,\n",
       "         0.62913564],\n",
       "       [-0.54994217, -0.2567713 , -0.58991159, -0.86337156, -1.07932778,\n",
       "        -0.65053565],\n",
       "       ...,\n",
       "       [ 0.53785553, -0.09965345,  2.38920103,  1.31372612,  0.92650261,\n",
       "        -0.29390594],\n",
       "       [-0.41396746, -0.23713157, -0.58991159, -0.89554542,  0.92650261,\n",
       "        -0.41977525],\n",
       "       [-0.68591688, -0.49244807,  0.89964472,  1.44242155, -1.07932778,\n",
       "        -0.27292772]])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss =StandardScaler()\n",
    "ss.fit(X_train)\n",
    "ss.transform(X_train)\n",
    "ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9661375661375662, 0.9634920634920635)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "logit.score(X_train, y_train), logit.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sod</th>\n",
       "      <th>pot</th>\n",
       "      <th>su</th>\n",
       "      <th>bgr</th>\n",
       "      <th>dm_yes</th>\n",
       "      <th>sc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.054458</td>\n",
       "      <td>0.24967</td>\n",
       "      <td>0.266959</td>\n",
       "      <td>0.022732</td>\n",
       "      <td>3.393282</td>\n",
       "      <td>3.477193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sod      pot        su       bgr    dm_yes        sc\n",
       "0 -0.054458  0.24967  0.266959  0.022732  3.393282  3.477193"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_\n",
    "features = ['sod', 'pot', 'su', 'bgr', 'dm_yes', 'sc']\n",
    "pd.DataFrame(logit.coef_, columns= features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = logit.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cells which reprsented the supposed unabalnced class have a much higher\n",
    "# reprsentation within the dataset. Part of it we can see that it proves \n",
    "# Our alt hypothesis about diabetes stronger. This is not good as it's misleading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "At this step, you would generally answer the problem! In this situation, you would likely present your model to doctors or administrators at the hospital and show how your model results in reduced false positives/false negatives. Next steps would be to find a way to roll this model and its conclusions out across the hospital so that the outcomes of patients with CKD (and without CKD!) can be improved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model has a 92% accuracy rate with 8% rate of false positives. This model\n",
    "# has much that could be improved upon especially in regards to increasing the\n",
    "# sensitivity rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
