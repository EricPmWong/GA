{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. \n",
    "- However, there are some additional questions along the way that don't fit neatly into the one main example we'll walk through. Any question that isn't explicitly part of the main example is marked with **(detour)** at the start of the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "Specifically, the professor says \"I need to prove that left-handedness is caused by some personality trait. Go find that personality trait and the data to back it up.\"\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### 1. In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "1. What is the psychopathology propesnsity ratio with occurence of left handed people?\n",
    "2. How does being left-handed increase the percentage probability of being bipolar?\n",
    "3. What is the probability decrease of having schizophrenia if you are left handed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 2. Read in the file titled \"data.csv.\"\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.962715</td>\n",
       "      <td>3.829589</td>\n",
       "      <td>2.846558</td>\n",
       "      <td>3.186902</td>\n",
       "      <td>2.865440</td>\n",
       "      <td>3.672084</td>\n",
       "      <td>3.216539</td>\n",
       "      <td>3.184512</td>\n",
       "      <td>2.761233</td>\n",
       "      <td>3.522945</td>\n",
       "      <td>...</td>\n",
       "      <td>479.994503</td>\n",
       "      <td>1.576243</td>\n",
       "      <td>1.239962</td>\n",
       "      <td>30.370698</td>\n",
       "      <td>2.317878</td>\n",
       "      <td>1.654398</td>\n",
       "      <td>1.833413</td>\n",
       "      <td>5.013623</td>\n",
       "      <td>2.394359</td>\n",
       "      <td>1.190966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.360291</td>\n",
       "      <td>1.551683</td>\n",
       "      <td>1.664804</td>\n",
       "      <td>1.476879</td>\n",
       "      <td>1.545798</td>\n",
       "      <td>1.342238</td>\n",
       "      <td>1.490733</td>\n",
       "      <td>1.387382</td>\n",
       "      <td>1.511805</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>...</td>\n",
       "      <td>3142.178542</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>0.440882</td>\n",
       "      <td>367.201726</td>\n",
       "      <td>0.874264</td>\n",
       "      <td>0.640915</td>\n",
       "      <td>1.303454</td>\n",
       "      <td>1.970996</td>\n",
       "      <td>2.184164</td>\n",
       "      <td>0.495357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>324.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>119834.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23763.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Q1           Q2           Q3           Q4           Q5  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      1.962715     3.829589     2.846558     3.186902     2.865440   \n",
       "std       1.360291     1.551683     1.664804     1.476879     1.545798   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     3.000000     1.000000     2.000000     1.000000   \n",
       "50%       1.000000     5.000000     3.000000     3.000000     3.000000   \n",
       "75%       3.000000     5.000000     5.000000     5.000000     4.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "                Q6           Q7           Q8           Q9          Q10  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      3.672084     3.216539     3.184512     2.761233     3.522945   \n",
       "std       1.342238     1.490733     1.387382     1.511805     1.242890   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       3.000000     2.000000     2.000000     1.000000     3.000000   \n",
       "50%       4.000000     3.000000     3.000000     3.000000     4.000000   \n",
       "75%       5.000000     5.000000     4.000000     4.000000     5.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "          ...          testelapse   fromgoogle       engnat           age  \\\n",
       "count     ...         4184.000000  4184.000000  4184.000000   4184.000000   \n",
       "mean      ...          479.994503     1.576243     1.239962     30.370698   \n",
       "std       ...         3142.178542     0.494212     0.440882    367.201726   \n",
       "min       ...            7.000000     1.000000     0.000000     13.000000   \n",
       "25%       ...          186.000000     1.000000     1.000000     18.000000   \n",
       "50%       ...          242.000000     2.000000     1.000000     21.000000   \n",
       "75%       ...          324.250000     2.000000     1.000000     27.000000   \n",
       "max       ...       119834.000000     2.000000     2.000000  23763.000000   \n",
       "\n",
       "         education       gender  orientation         race     religion  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      2.317878     1.654398     1.833413     5.013623     2.394359   \n",
       "std       0.874264     0.640915     1.303454     1.970996     2.184164   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     1.000000     1.000000     5.000000     1.000000   \n",
       "50%       2.000000     2.000000     1.000000     6.000000     2.000000   \n",
       "75%       3.000000     2.000000     2.000000     6.000000     2.000000   \n",
       "max       4.000000     3.000000     5.000000     7.000000     7.000000   \n",
       "\n",
       "              hand  \n",
       "count  4184.000000  \n",
       "mean      1.190966  \n",
       "std       0.495357  \n",
       "min       0.000000  \n",
       "25%       1.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       3.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', delim_whitespace=1)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>409</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23763</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...   country  fromgoogle  \\\n",
       "2075   3   4   5   4   3   4   5   4   3    3  ...        US           2   \n",
       "2137   1   2   5   4   3   1   5   1   5    3  ...        US           2   \n",
       "2690   2   5   5   1   5   5   5   5   4    2  ...        US           2   \n",
       "\n",
       "      engnat    age  education  gender  orientation  race  religion  hand  \n",
       "2075       1    123          1       1            5     7         7     3  \n",
       "2137       1    409          2       1            5     6         1     1  \n",
       "2690       2  23763          4       1            2     7         7     0  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There looks to be some odd values for age above 99.\n",
    "df[df['age'] > 99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will assume first to numbers are true age\n",
    "df.iloc[2075, df.columns.get_loc('age')] = 12\n",
    "df.iloc[2137, df.columns.get_loc('age')] = 40\n",
    "df.iloc[2690, df.columns.get_loc('age')] = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4184.000000\n",
       "mean       24.581979\n",
       "std        10.870193\n",
       "min        12.000000\n",
       "25%        18.000000\n",
       "50%        21.000000\n",
       "75%        27.000000\n",
       "max        86.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suppose that, instead of us giving you this data in a file, you were actually conducting a survey to gather this data yourself. From an ethics/privacy point of view, what are three things you might consider when attempting to gather this data?\n",
    "> When working with sensitive data like sexual orientation or gender identity, we need to consider how this data could be used if it fell into the wrong hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "1. Obsficating the religion so that instead of it's actual name it could be a replaced variable. Since relgion can be used for political agendas.\n",
    "2. Gender could also something that might need to be either eliminated (if it's found to be a non-variable in dataset) or replaced with 1 and 0s to hide which gender is being talked about.\n",
    "3. Orientation would be another factor that needs to be carefully considered. It can be a very sensitive and private choice for some, so even implying a personality connection with left-handness would have to be considered carefully. As well with other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 4. Conduct exploratory data analysis on this dataset.\n",
    "> If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "introelapse    330.381990\n",
       "testelapse     149.124335\n",
       "age              1.320833\n",
       "hand             1.000000\n",
       "Q8               0.217961\n",
       "Q22              0.184292\n",
       "Q43              0.179986\n",
       "Q42              0.171075\n",
       "Q4               0.161624\n",
       "Q23              0.158254\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lefthand = df[df.hand ==2]\n",
    "righthand = df[df.hand == 1]\n",
    "topdif = lefthand.mean() - righthand.mean()\n",
    "abs(topdif).sort_values(ascending=False).head(10)\n",
    "# Got the average of each catergory for lefthanded and compared it to the Righthanded average. The largest differences should reflect the biggest difference between \n",
    "#handnesses. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8               0.217961 I know the birthdays of my friends. \n",
    "#Q22              0.184292 I save the letters I get\n",
    "#Q43              0.179986 I think a natural disaster would be kind of exciting\n",
    "#Q42              0.171075 I bake sweets just for myself sometimes.\n",
    "#Q4               0.161624 I give people handmade gifts.\n",
    "#Q23              0.158254 I playfully insult my friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Q8', 'Q22', 'Q43', 'Q42', 'Q4', 'Q23']\n",
    "lefthand[features].mean(),\n",
    "compared = pd.DataFrame()\n",
    "compared['rh'] = righthand[features].mean()\n",
    "compared['lf'] = lefthand[features].mean()\n",
    "compared['dif'] = compared['rh'] - compared['lf']\n",
    "compared.index = ['Fr Bday', 'Letters', 'Dist +', 'Self Bake', 'Crap gifts', 'Insult']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.title('Biggest differences in personality traits from Left and Right handers');\n",
    "sns.barplot(x=compared.index, y=compared['dif'], data=compared, color='b');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 5. Suppose I wanted to use Q1 - Q44 to predict whether or not the person is left-handed. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Classification because lefthandness is a nominal catergorial variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (detour) 6. While this isn't the problem we set out to solve, suppose I wanted to predict the exact age of the respondent using Q1 - Q44 as my predictors. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: It could be regression depending on how to look at it. Since the Y target is age, we could evaluate X based on Questions on the X. Since the value of Righthandness wouldn't be too pertinent to the analysis and not dependent on it, we would not have a classification target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed based on their responses to Q1 - Q44. Before doing that, however, you remember that it is often a good idea to standardize your variables. In general, why would we standardize our variables? Give an example of when we would standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Standarizing variables is necessary for KNN with Eucledian because standization makes all variables contribute equally. in general it's a good idea in order to get equal contribution weights and to make sure that one variable will not contribute more than others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Give an example of when we might not standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: If the units on features is meaningful and the distance makes a difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Based on your answers to 7 and 8, do you think we should standardize our predictor variables in this case? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Yes because I've read that KNN is dependent on using SS to make all variables contribute equally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed. What munging/cleaning do we need to do to our $y$ variable in order to explicitly answer this question? Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We need to set the target to be only left handed and the other target to be not left handed. Already did it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. The professor for whom you work suggests that you set $k = 4$. Why might this be a bad idea in this specific case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Since the difference between left and right handed people is so minute, using a large knn might make it too broad and introduce too much bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Let's *(finally)* use $k$-nearest neighbors to predict whether or not a person is left-handed!\n",
    "\n",
    "> Be sure to create a train/test split with your data!\n",
    "\n",
    "> Create four separate models, one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$.\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "df['target'] = [1 if x == 2 else 0 for x in df['hand']]\n",
    "y = df['target']\n",
    "features = ['Q' + str(x) for x in range(1, 45) ]\n",
    "X = df[features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X)\n",
    "X_train =ss.transform(X_train)\n",
    "X_test =ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-marts Nearest Neighbor 3 ====\n",
      "Model Accuracy:  0.9069471000637349\n",
      "Test Accuracy:  0.858508604206501\n",
      "R2 Score:  -0.5801894496162017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "knnpred = knn.predict(X_test)\n",
    "print('=== K-marts Nearest Neighbor 3 ====')\n",
    "print('Model Accuracy: ', knn.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', knn.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, knnpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-marts Nearest Neighbor 5 ====\n",
      "Model Accuracy:  0.8887826641172721\n",
      "Test Accuracy:  0.8862332695984704\n",
      "R2 Score:  -0.2705577331373512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "knnpred = knn.predict(X_test)\n",
    "print('=== K-marts Nearest Neighbor 5 ====')\n",
    "print('Model Accuracy: ', knn.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', knn.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, knnpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-marts Nearest Neighbor 15 ====\n",
      "Model Accuracy:  0.8891013384321224\n",
      "Test Accuracy:  0.8996175908221797\n",
      "R2 Score:  -0.12108035276825113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "knn.fit(X_train, y_train)\n",
    "knnpred = knn.predict(X_test)\n",
    "print('=== K-marts Nearest Neighbor 15 ====')\n",
    "print('Model Accuracy: ', knn.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', knn.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, knnpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== K-marts Nearest Neighbor 25 ====\n",
      "Model Accuracy:  0.8891013384321224\n",
      "Test Accuracy:  0.9005736137667304\n",
      "R2 Score:  -0.11040339702760105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 25)\n",
    "knn.fit(X_train, y_train)\n",
    "knnpred = knn.predict(X_test)\n",
    "print('=== K-marts Nearest Neighbor 25 ====')\n",
    "print('Model Accuracy: ', knn.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', knn.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, knnpred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being good data scientists, we know that we might not run just one type of model. We might run many different models and see which is best.\n",
    "\n",
    "### 13. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, let's check the [documentation for logistic regression in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Is there default regularization? If so, what is it? If not, how do you know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes it's default to \"penalty\" to L2 which is ridge. I know because it's the default?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ====\n",
      "\n",
      "Model Accuracy:  0.8891013384321224\n",
      "Test Accuracy:  0.9005736137667304\n",
      "R2 Score:  -0.11040339702760105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "logitpred = logit.predict(X_test)\n",
    "print('=== Logistic Regression ====')\n",
    "print()\n",
    "print('Model Accuracy: ', logit.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', logit.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, logitpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.596764</td>\n",
       "      <td>0.403236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "73  0.596764  0.403236"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick check on odds\n",
    "a = pd.DataFrame(logit.predict_proba(X_test))\n",
    "a[a[1]>.40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, should we standardize our features? Well, the answer is (as always), **it depends**. What is one reason you would standardize? What is one reason you would not standardize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "- An example of when I would standardize in logistic regression is when we are dealing with different y values per feature\n",
    "- An example of when I would not standardize in logistic regression is when we are dealing with same y values per feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Let's use logistic regression to predict whether or not the person is left-handed.\n",
    "\n",
    "\n",
    "> Be sure to use the same train/test split with your data as with your $k$-NN model above!\n",
    "\n",
    "> Create four separate models, one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lasso Alpha 1 ====\n",
      "Model Accuracy:  0.8891013384321224\n",
      "Test Accuracy:  0.9005736137667304\n",
      "R2 Score:  -0.11040339702760105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "l1 = LogisticRegression(penalty='l1', C=.99)\n",
    "l1.fit(X_train, y_train)\n",
    "l1pred =l1.predict(X_test)\n",
    "print('=== Lasso Alpha 1 ====')\n",
    "print('Model Accuracy: ', l1.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', l1.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, l1pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Lasso Alpha 10 ====\n",
      "Model Accuracy:  0.8891013384321224\n",
      "Test Accuracy:  0.9005736137667304\n",
      "R2 Score:  -0.11040339702760105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "l10 = LogisticRegression(penalty='l1', C= .10)\n",
    "l10.fit(X_train, y_train)\n",
    "l10pred =l10.predict(X_test)\n",
    "print('=== Lasso Alpha 10 ====')\n",
    "print('Model Accuracy: ', l10.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', l10.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, l10pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ridge Alpha 1 ====\n",
      "Model Accuracy:  0.8891013384321224\n",
      "Test Accuracy:  0.9005736137667304\n",
      "R2 Score:  -0.11040339702760105\n"
     ]
    }
   ],
   "source": [
    "r1 = LogisticRegression(penalty='l2', C= .99)\n",
    "r1.fit(X_train, y_train)\n",
    "r1pred =r1.predict(X_test)\n",
    "print('=== Ridge Alpha 1 ====')\n",
    "print('Model Accuracy: ', r1.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', r1.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, r1pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ridge Alpha 10 ====\n",
      "\n",
      "Model Accuracy:  0.8891013384321224\n",
      "Test Accuracy:  0.9005736137667304\n",
      "R2 Score:  -0.11040339702760105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "r10 = LogisticRegression(penalty='l2', C= .10)\n",
    "r10.fit(X_train, y_train)\n",
    "r10pred =r10.predict(X_test)\n",
    "print('=== Ridge Alpha 10 ====')\n",
    "print()\n",
    "print('Model Accuracy: ', r10.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', r10.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, r10pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate the model(s).\n",
    "\n",
    "### 16. Before calculating any score on your data, take a step back. Think about your $X$ variable and your $Y$ variable. Do you think your $X$ variables will do a good job of predicting your $Y$ variable? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: No, I have several reasons to believe that the X variable is not indicative of predicting handness. The data doesn't seem to support it and also we went into the survey with the assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Using accuracy as your metric, evaluate all eight of your models on both the training and testing sets. Put your scores below. (If you want to be fancy and generate a table in Markdown, there's a [Markdown table generator site linked here](https://www.tablesgenerator.com/markdown_tables#).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| k_neighbor | 3   | 5   | 15  | 25  |\n",
    "|------------|-----|-----|-----|-----|\n",
    "| TRAIN      | .90 | .90 | .89 | .89 |\n",
    "| Test       | .84 | .87 | .89 | .89 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. In which of your $k$-NN models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: KNN 3 has some overfitting because the model is higher than the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Broadly speaking, how does the value of $k$ in $k$-NN affect the bias-variance tradeoff? (i.e. As $k$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Smaller values of KNN makes the model more fit to the training. However it makes it less bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. If you have a $k$-NN model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 1You may want to try increasing KNN. Low KNN overfits 2, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. In which of your logistic regression models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Yes in all of them they are overfit because the model is higher than the test data in all alpha cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. Broadly speaking, how does the value of $C$ in logistic regression affect the bias-variance tradeoff? (i.e. As $C$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: As C increases (meaning Alpha decreases), we create a more varied model. Since decreasing alpha means we create more variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. For your logistic regression models, play around with the regularization hyperparameter, $C$. As you vary $C$, what happens to the fit and coefficients in the model? What might this mean in the context of this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ridge Alpha 10 ====\n",
      "\n",
      "Model Accuracy:  0.8891013384321224\n",
      "Test Accuracy:  0.9005736137667304\n",
      "R2 Score:  -0.11040339702760105\n"
     ]
    }
   ],
   "source": [
    "las = LogisticRegression(penalty='l1', C= .00000000000000001)\n",
    "las.fit(X_train, y_train)\n",
    "laspred =las.predict(X_test)\n",
    "print('=== Ridge Alpha 10 ====')\n",
    "print()\n",
    "print('Model Accuracy: ', las.score(X_train, y_train)) \n",
    "print('Test Accuracy: ', las.score(X_test, y_test))\n",
    "print('R2 Score: ', r2_score(y_test, laspred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Altering the C doesn't change much. This likely might mean that because since the alpha isn't affecting the model, it could be that our model is not overly complex to begin with and that any efforts to reduce it's complexity will not make it any more bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. If you have a logistic regression model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Lasso, ridge, and increasing or decaresing n_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "### 25. Suppose you want to understand which psychological features are most important in determining left-handedness. Would you rather use $k$-NN or logistic regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Because I want to find out which feature is most important, I would use logistic regresson model. I want to get the features of impact instead of a classification model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. Select a logistic regression model. Interpret the coefficient for `Q1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01174148280260706"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.coef_[0][0]\n",
    "# This coefficent means that as Q1 goes up, the probablility this person is left hand is likely going down by 5.4%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. If you have to select one model overall to be your *best* model, which model would you select? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: KNN with K_n=15. It looks like predicted and model are closest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. Circle back to the three specific and conclusively answerable questions you came up with in Q1. Answer these for the professor based on the model you selected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is the psychopathology propesnsity ratio with occurence of left handed people?\n",
    "## High they really enjoy, insulting people \n",
    "### 2. How does being left-handed increase the percentage probability of being bipolar?\n",
    "## Not determinable from data\n",
    "### 3. What is the probability decrease of having schizophrenia if you are left handed?\n",
    "## Not determinable from data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Looking for more to do? Probably not - you're busy! But if you want to, consider exploring the following:\n",
    "- Suppose this data were in a `SQL` database named `data` and a table named `inventory`. What `SQL` query would return the count of people who were right-handed, left-handed, both, or missing with their class labels of 1, 2, 3, and 0, respectively? (You can assume you've already logged into the database.)\n",
    "- Fit and evaluate one or more of the generalized linear models discussed above.\n",
    "- Create a plot comparing training and test metrics for various values of $k$ and various regularization schemes in logistic regression.\n",
    "- Rather than just evaluating models based on accuracy, consider using sensitivity, specificity, etc.\n",
    "- In the context of predicting left-handedness, why are unbalanced classes concerning? If you were to re-do this process given those concerns, what changes might you make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
